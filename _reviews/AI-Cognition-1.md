---
title:  "AI Cognition 1"
date:   2025-07-17 10:00:00 +0200
tags:   [AI, machine-learning]
layout: post
label_color: blue
---

AI Cognition 1

Can LLMs Understand as we do?

Large language models have elicited countless questions about how we understand cognition. The main finding discussed in the source material is that LLMs develop complex skills through emergence and are not stochastic parrots as some claimed. This parallels how human cognition is thought to emerge as a pattern of coordination among different neural processes and representations. However, when can we really say that artificial intelligence is equivalent to human intelligence? Do we need to confirm that an AI can do the exact same tasks as a human in the exact same way to deem them equal? Or will we engineer another barrier to preserve a humanist distinction?




-----Sources and additional information-------
Writing bewteen 80 and 120 words inspired by the following source:

- New Theory Suggests Chatbots Can Understand Text
https://www.quantamagazine.org/new-theory-suggests-chatbots-can-understand-text-20240122/

- 2024's Biggest Breakthroughs in Computer Science - QuantaMagazine (Youtube)
https://www.youtube.com/watch?v=fTMMsreAqX0

- Chatgpt chat discussion
https://chatgpt.com/share/688a3b16-a2c8-800f-93f1-3edfb5c5cd5a
 ---------------------------------------------
